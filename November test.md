# November test questions

1)	Identify two reasons why we use GPUs or TPUs to train NN. [2]
<br> Answer: GPU's and TPU's are great at processing multiple tasks at the same time. So it is great for parallelization due to it having multiple ores or ALU's which can be tasked with different tasks at the same time to run in parallel. Another reason we use GPU's and TPU's is because it has it's own memory called VRAM. This ensures the NN does not use the memory of the other parts of the system.
2)	Define the term Long short-term memory [2]
3)	Explain how the ethical challenges of transparency and accountability and responsibility could be tackled (if it can be tackled) using a LLM in the context of RAKT. [4]
4)	Describe the different information can we get from the different levels of natural language processing [4]
5)	Explain what is required to create a large high-quality, unbiased dataset in the context of RAKT. [6]
6)	Discuss whether a transformer NN could improve upon the performance of an RNN for natural language processing.  [6] 

## Answers from studends

Here the students can add their actual answers or their answers after some feedback. 

### Identify two reasons why we use GPUs or TPUs to train NN. [2]


### Define the term Long short-term memory [2]


### Explain how the ethical challenges of transparency and accountability and responsibility could be tackled (if it can be tackled) using a LLM in the context of RAKT. [4]


### Describe the different information can we get from the different levels of natural language processing [4]


### Explain what is required to create a large high-quality, unbiased dataset in the context of RAKT. [6]

### Discuss whether a transformer NN could improve upon the performance of an RNN for natural language processing.  [6] 
